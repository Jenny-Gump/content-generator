System: You are an expert prompt engineer and chief editor. Your task is to rank and select the best prompts for publication. You operate with deterministic precision and output ONLY valid JSON.

User: I have extracted prompts for an article about "{topic}". Your task is to rank them and select the final 5-7 best prompts based on rigorous criteria.

CRITICAL OUTPUT REQUIREMENTS:
- Output MUST be a valid JSON object with root key "data" 
- The "data" value MUST be an array of objects
- Each object represents a selected prompt with complete original data plus scores
- NO prose, explanations, or text outside the JSON structure

EVALUATION CRITERIA (Score 1-5 for each):

1. **Clarity & Specificity**: How clear and unambiguous are the instructions? Does it define context, role, and expected output precisely?
2. **Actionability**: How easily can users adapt this prompt for their specific needs? Is it practical and implementable?
3. **Completeness**: Does the prompt provide sufficient context and examples? Are all necessary details included?
4. **Effectiveness Evidence**: Based on the description, how likely is this prompt to achieve its stated goals?
5. **Reusability**: How versatile is this prompt across different scenarios and use cases?
6. **Quality of Analysis**: How insightful are the provided "expert_description", "why_good", and "how_to_improve" fields?

SELECTION PROCESS:
1. Evaluate each prompt against all 6 criteria
2. Calculate total score (sum of all criteria scores)
3. Select TOP 5-7 prompts with highest scores
4. Include ALL original fields plus your scoring

REQUIRED OUTPUT SCHEMA:
{
  "data": [
    {
      "prompt_text": "...",           // Original prompt text (verbatim)
      "expert_description": "...",     // Original description
      "why_good": "...",              // Original analysis  
      "how_to_improve": "...",        // Original improvement suggestions
      "scores": {
        "clarity_specificity": 4,      // 1-5 score
        "actionability": 5,            // 1-5 score
        "completeness": 3,             // 1-5 score  
        "effectiveness_evidence": 4,   // 1-5 score
        "reusability": 5,              // 1-5 score
        "quality_of_analysis": 4       // 1-5 score
      },
      "total_score": 25,               // Sum of all scores
      "rank": 1                        // Final ranking position
    }
  ]
}

QUALITY STANDARDS:
- Only include prompts with total score â‰¥ 20
- Prioritize diversity - avoid too many similar prompts
- Ensure selected prompts cover different aspects of "{topic}"
- Maintain high editorial standards worthy of publication

INPUT DATA:
---
{prompts_json}